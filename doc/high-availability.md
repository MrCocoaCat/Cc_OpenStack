()[]https://docs.openstack.org/ha-guide/
### OpenStack高可用介绍
高可用系统力求将以下问题最小化
1. 系统停机时间：用户所使用的服务器在一段时间内无法使用
2. 数据丢失：数据被意外删除或销毁
大多数高可用系统在单个故障生时可以提供保护，即防止关机或数据丢失。然后进行故障联防是十分必要的，即防止单个故障恶化为更严重的后续故障。许多服务提供Service Level Agreement (SLA)，其中包括计算服务的正常运行时间百分比，该百分比是根据可用时间和系统停机时间(不包括计划停机时间)计算的。
####冗余和故障转移（Redundancy and failover）
高可用性是通过运行每个服务的冗余实例的冗余硬件实现的。
如果运行一个服务实例的硬件部分发生故障，系统就可以进行故障转移，以使用运行在没有发生故障的硬件上的另一个服务实例。高可用性的一个关键方面是消除单点故障(SPOFs)。
SPOF是一种单独的设备或软件，如果出现故障，会导致系统停机或数据丢失。为了消除SPOFs，检查是否存在冗余机制:
* 网络组件，如交换机和路由器
* 应用程序和自动服务迁移
* 存储组件
* 电力、空调、消防等服务设施
如果组件发生故障，备份系统必须承担其负载，大多数高可用性系统将尽快替换失败的组件，以保持必要的冗余。这样，在降级保护状态下所花费的时间就会最小化。
大多数高可用性系统在出现多个独立故障时发生整体性故障。在这种情况下，大多倾向于保护数据而不是维护可用性。
高可用性系统通常可实现99.99％或更高的正常运行时间百分比，这大致相当于每年不到一小时的累计停机时间。 为了实现这一目标，高可用性系统应该在故障发生后将恢复时间保持在大约一到两分钟，有时甚至更少。OpenStack目前满足其自身基础架构服务的可用性要求，这意味着OpenStack基础架构正常运行99.99％的正常运行时间。 但是，OpenStack不保证单个访问实例的99.99％可用性。
本文档讨论了实现高可用性系统的一些常用方法，重点是核心OpenStack服务以及与OpenStack紧密结合的其他开源服务。

您需要解决在OpenStack环境中运行的任何应用程序软件的高可用性问题，重要的是确保您的服务冗余且可用。

#### 无状态和有状态服务(Stateless versus stateful services)

* active/passive configuration
维护可在活动服务失败时联机的冗余实例。 例如，OpenStack在维护灾难恢复数据库的同时写入主数据库，如果主数据库发生故障，该数据库可以联机。有状态服务的典型主动/被动安装维护可在需要时联机的替换资源。 使用虚拟IP地址（VIP）处理请求，这有助于以最小的重新配置返回服务。 单独的应用程序（如Pacemaker或Corosync）会监视这些服务，并在必要时将备份联机。
* active/active configuration
每个服务均具有一份，其同时管理主系统和冗余系统。发生故障時，用户可能並不會察覺。 在主系统修复之前,备份系统已经在线运行,并承担提升的负载。

通常，无状态服务的主动/主动安装维护冗余实例，并使用虚拟IP地址和负载平衡器（如HAProxy）对请求进行负载平衡。

有状态服务的典型主动/主动安装包括冗余服务，所有实例具有相同的状态。
换句话说，对数据库的一个实例的更新会更新所有其他实例。
这样，对一个实例的请求与对任何其他实例的请求相同。 负载均衡器管理这些系统的流量，确保操作系统始终处理请求。

#### 集群及数量 Clusters and quorums

quorum指定冗余节点集群中必须具有功能的节点的最小数量，以便集群保持功能。当一个节点发生故障，故障转移将控制转移到其他节点时，系统必须确保数据和进程保持正常。为了确定这一点，将比较剩余节点的内容，如果存在差异，则执行一个多数规则算法。因此，高可用性环境中的每个集群都应该有奇数个节点，并且quorum定义为超过一半的节点。如果多个节点失败，以致集群大小低于仲裁值，那么集群本身就会失败。
例如，在一个7节点集群中，应该将quorum设置为floor(7/2) + 1 == 4。如果quorum是4，同时有4个节点失败，那么集群本身就会失败，而如果不超过3个节点失败，它将继续运行。如果分别划分为3个和4个节点的分区，那么4个节点的quorum将继续操作多数分区，并停止或隔离少数分区(取决于无quorum-policy集群配置)。

当四个节点同时失败时，集群也将继续工作。但是，如果分别划分为3个节点和4个节点，那么3个节点的quorum将使双方都试图隔离其他节点和主机资源。如果不启用隔离，将直接运行每个资源的两个副本。
这就是为什么将quorum设置为小于floor(n/2) + 1是危险的。但是，对于某些特定的情况，可能需要这样做，例如在一个节点上，我们100%确定其他节点已经关闭了。在作为研究或演示而配置OpenStack环境时，可以关闭quorum检查。生产环境下应该在启用quorum的情况下运行。

#### Single-controller高可用性模式
OpenStack支持由管理高可用性环境的服务管理的单控制器高可用性模式，但实际上不是高可用性模式，因为没有配置冗余控制器用于故障转移。此环境可用于研究和演示，但不适用于生产环境。可以向这样的环境添加控制器，将其转换为真正高可用的环境。高可用性并不是对每个用户都适用。它带来了一些挑战。对于具有大量数据的数据库或系统来说，高可用性可能过于复杂。复制会减慢大型系统的速度。不同的设置有不同的先决条件。

### 高可用性的硬件配置
OpenStack不需要大量的资源,具有核心服务和几个实例的高可用性环境应以下最低要求应支持

| Node type          | 核心数 |  内存 | 硬盘 | NIC|
| --------           | :---: |  :--:| :---:|:--:|
| controller node    | 4     | 12G  |120G  |2   |
| compute node       | 8+    | 12+G |120+G |2   |

我们建议任何两个控制器节点之间的最大延迟为2毫秒。虽然集群软件可以调优到更高的延迟，但一些供应商在同意支持安装之前坚持这个值。您可以使用ping命令查找两个服务器之间的延迟。
### 虚拟硬件设置

为了演示和学习，您可以在虚拟机(VMs)上设置测试环境。这有以下好处:


一个物理服务器可以支持多个节点，每个节点几乎支持任意数量的网络接口。您可以在整个安装过程中定期进行快照，并在出现问题时回滚到工作配置。但是，在vm上运行OpenStack环境会降低实例的性能，特别是当您的管理程序或处理器不支持嵌套vm的硬件加速时。
